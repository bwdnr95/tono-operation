# backend/app/services/auto_reply_service.py
from __future__ import annotations
import asyncio
import json
import logging
from dataclasses import dataclass, asdict, is_dataclass

from typing import Optional, Tuple, Any, Dict

from sqlalchemy import desc, select
from sqlalchemy.orm import Session

from app.domain.intents import (
    MessageIntent,
    FineGrainedIntent,
    MessageActor,
    MessageActionability,
)
from app.domain.intents.auto_action import MessageActionType
from app.domain.intents.types import IntentLabelSource  # âœ… ì—¬ê¸°! (backend. ë¹ ì§)

from app.repositories.messages import IncomingMessageRepository
from app.repositories.property_profile_repository import PropertyProfileRepository
from app.repositories.auto_reply_template_repository import AutoReplyTemplateRepository
from app.repositories.staff_notification_repository import StaffNotificationRepository
from app.repositories.auto_reply_log_repository import AutoReplyLogRepository
from app.repositories.message_intent_labels import (
    MessageIntentLabelRepository,
)  # âœ… fine_intent ë¼ë²¨ ê¸°ë¡ìš©

from app.services.airbnb_intent_classifier import (
    AirbnbIntentClassifier,
    HybridIntentResult,
)
from app.services.intent_action_decider import IntentActionDecider
from app.services.reply_context_builder import ReplyContextBuilder, ReplyContext
from app.services.llm_intent_classifier import FineGrainedIntentResult
from app.services.closing_message_detector import ClosingMessageDetector
from app.domain.models.staff_notification import StaffNotification
from app.core.config import settings
from app.domain.models.incoming_message import IncomingMessage

logger = logging.getLogger(__name__)

@dataclass(slots=True)
class AutoReplySuggestion:
    message_id: int
    intent: MessageIntent
    fine_intent: Optional[FineGrainedIntent]
    intent_confidence: float
    reply_text: str
    template_id: Optional[int]
    # "template" | "llm_with_template" | "llm_no_template" | "no_template_fallback"
    generation_mode: str
    action: MessageActionType
    allow_auto_send: bool
    is_ambiguous: bool


class AutoReplyService:
    """
    TONO AutoReply ì—”ì§„.

    ì—­í• :
      1) ë©”ì‹œì§€ Intent (primary + fine)ë¥¼ í™•ë³´
      2) PropertyProfile ê¸°ë°˜ ReplyContext êµ¬ì„±
      3) í…œí”Œë¦¿/LLM í•˜ì´ë¸Œë¦¬ë“œë¡œ ë‹µë³€ í…ìŠ¤íŠ¸ ìƒì„±
      4) Intent â†’ ActionDeciderë¡œ ì•¡ì…˜ ê²°ì • (AUTO_REPLY / STAFF_ALERT ë“±)
    """

    def __init__(self, db: Session) -> None:
        self._db = db
        self._msg_repo = IncomingMessageRepository(db)
        self._property_repo = PropertyProfileRepository(db)
        self._template_repo = AutoReplyTemplateRepository(db)

        self._intent_classifier = AirbnbIntentClassifier()
        self._action_decider = IntentActionDecider()
        self._context_builder = ReplyContextBuilder(db)

        # ğŸ”½ ê¸°ì¡´ì—ëŠ” self._llm ì´ë¼ëŠ” í•„ë“œë¥¼ ìƒì •í•˜ê³  ìˆì—ˆëŠ”ë°,
        # í˜„ì¬ AutoReplyServiceëŠ” ë‚´ë¶€ì—ì„œ ì§ì ‘ OpenAI SDKë¥¼ ì‚¬ìš©í•˜ê³  ìˆìœ¼ë©°
        # LLMClient ì¸ìŠ¤í„´ìŠ¤ë¥¼ ê³µìœ í•˜ì§€ ì•ŠëŠ”ë‹¤.
        # ClosingMessageDetectorë„ LLMClient ì˜ì¡´ì„±ì„ ì œê±°í–ˆê¸° ë•Œë¬¸ì—
        # ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœ ê¸°ë³¸ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•´ì„œ ì‚¬ìš©í•˜ë©´ ëœë‹¤.
        self.closing_detector = ClosingMessageDetector()

        self._auto_reply_log_repo = AutoReplyLogRepository(db)
        self._intent_label_repo = MessageIntentLabelRepository(db)
        self._auto_reply_mode = getattr(settings, "AUTO_REPLY_MODE", "AUTOPILOT").upper()

    # ------------------------------------------------------------------
    # Public API
    # ------------------------------------------------------------------

    async def _build_staff_notification(
        self,
        *,
        message,
        context: ReplyContext,
        primary_intent: MessageIntent,
        fine_intent: Optional[FineGrainedIntent],
        reply_text: str,
    ) -> Optional[StaffNotification]:
        """
        ê²ŒìŠ¤íŠ¸ ë©”ì‹œì§€ + Intent + ReplyContextë¥¼ ê¸°ë°˜ìœ¼ë¡œ
        ìš´ì˜íŒ€ Follow-up ì•Œë¦¼(StaffNotification)ì„ ìƒì„±í•œë‹¤.
        """

        actions = await self._extract_follow_up_actions_with_llm(
            message_text=message.pure_guest_message or "",
            primary_intent=primary_intent,
            fine_intent=fine_intent,
            reply_text=reply_text,
            context=context,
        )

        if not actions:
            return None

        # ğŸ”¹ guest_name ìµœëŒ€í•œ ì±„ìš°ê¸°
        guest_name = getattr(message, "guest_name", None)

        # í•„ìš”í•˜ë©´ ì—¬ê¸°ì„œ from_email íŒŒì‹± ë“± ì¶”ê°€ ê°€ëŠ¥
        # ex) "í™ê¸¸ë™ via Airbnb <xxx@xxx>" í˜•íƒœì—ì„œ ì•ë¶€ë¶„ë§Œ ë–¼ëŠ” ë¡œì§ ë“±

        checkin_date = getattr(message, "checkin_date", None)
        checkout_date = getattr(message, "checkout_date", None)

        return StaffNotification(
            property_code=context.property_code,
            ota=message.ota,
            guest_name=guest_name,
            checkin_date=str(checkin_date) if checkin_date else None,
            checkout_date=str(checkout_date) if checkout_date else None,
            message_summary=(message.pure_guest_message or "")[:120],
            follow_up_actions=actions,
        )
    def _closing_static_reply(self, locale: str) -> tuple[str, str]:
        """
        'ëŒ€í™” ì¢…ë£Œìš© ê°ì‚¬ ì¸ì‚¬' ê³ ì • ë‹µë³€ì„ ë°˜í™˜.
        - closing_detector ê°€ is_closing=True ì¸ ê²½ìš°ì—ë§Œ ì‚¬ìš©.
        - (reply_text, generation_mode) íŠœí”Œë¡œ ë°˜í™˜.
        """
        if locale.startswith("ko"):
            reply_text = (
                "ê°ì‚¬í•©ë‹ˆë‹¤! ì¼ì • ê°„ í–‰ë³µë§Œ ê°€ë“í•˜ì‹œê¸¸ ê¸°ë„í•˜ê² ìŠµë‹ˆë‹¤ :) "
                "ë‹¤ë¥¸ ë¬¸ì˜ì‚¬í•­ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ì—°ë½ ë‚¨ê²¨ì£¼ì„¸ìš”!"
            )
        else:
            reply_text = (
                "Thank you! Wishing you nothing but happiness throughout your stay :) "
                "If you have any questions, please feel free to contact us anytime!"
            )

        # generation_modeëŠ” ë¡œê·¸/ë¶„ì„ìš© íƒœê·¸
        return reply_text, "closing_static"

    async def suggest_reply_for_message(
        self,
        *,
        message_id: int,
        ota: Optional[str] = None,
        locale: str = "ko",
        property_code: Optional[str] = None,
        use_llm: bool = True,
    ) -> Optional[AutoReplySuggestion]:
        """
        ë©”ì‹œì§€ 1ê±´ì— ëŒ€í•œ ìë™ì‘ë‹µ ì´ˆì•ˆì„ ë§Œë“ ë‹¤.
        - ì‹¤ì œ ë°œì†¡ì€ ì´ ê²°ê³¼ë¥¼ ë³´ê³  í”„ë¡ íŠ¸/ìš´ì˜íˆ´ì—ì„œ ê²°ì •.
        """

        msg = self._msg_repo.get(message_id)
        if not msg:
            return None

        # âœ… ì¶”ê°€: ê²ŒìŠ¤íŠ¸ê°€ ì•„ë‹ˆê±°ë‚˜, ë‹µì¥ì´ í•„ìš” ì—†ëŠ” ë©”ì‹œì§€ëŠ” ìë™ì‘ë‹µ ëŒ€ìƒì—ì„œ ì œì™¸
        if msg.sender_actor != MessageActor.GUEST:
            logger.info(
                "AUTOREPLY_SKIP(non-guest): message_id=%s actor=%s",
                message_id,
                msg.sender_actor,
            )
            return None

        if msg.actionability != MessageActionability.NEEDS_REPLY:
            logger.info(
                "AUTOREPLY_SKIP(non-needs-reply): message_id=%s actionability=%s",
                message_id,
                msg.actionability,
            )
            return None

        # íŠ¹ë³„ ì¼€ì´ìŠ¤: ì¢…ë£Œ ì¸ì‚¬ ê°ì§€
        closing = await self.closing_detector.detect(msg.pure_guest_message)

        if closing.is_closing:
            primary_intent = MessageIntent.THANKS_OR_GOOD_REVIEW
            fine_intent = FineGrainedIntent.GENERAL_THANKS
            reply_text, generation_mode = self._closing_static_reply(locale=locale)

            return AutoReplySuggestion(
                message_id=message_id,
                intent=primary_intent,
                fine_intent=fine_intent,
                intent_confidence=0.95,
                reply_text=reply_text,
                action=MessageActionType.AUTO_REPLY,
                allow_auto_send=True,
                template_id=None,
                is_ambiguous=False,
                generation_mode=generation_mode,
            )

        # 1) Intent (primary + fine) í™•ë³´
        primary_intent, fine_intent, intent_conf, is_ambiguous = self._ensure_intent(
            msg_id=message_id,
            ota=ota or msg.ota,
        )

        # Intentê°€ ì •ë§ë¡œ OTHERì´ê³ , pure_guest_messageë„ ê±°ì˜ ë¹„ì–´ ìˆìœ¼ë©´ â†’ êµ³ì´ ì‘ë‹µ ë§Œë“¤ í•„ìš” ì—†ìŒ
        if primary_intent == MessageIntent.OTHER and not (msg.pure_guest_message or "").strip():
            return None

        # 2) ReplyContext êµ¬ì„± (PropertyProfile selection í¬í•¨)
        context = self._context_builder.build_for_message(
            message_id=message_id,
            primary_intent=primary_intent,
            fine_intent=fine_intent,
            locale=locale,
            explicit_property_code=property_code,
        )

        # OTA â†’ channel ë§¤í•‘ (ì§€ê¸ˆì€ ë‹¨ìˆœíˆ ota ê·¸ëŒ€ë¡œ ì‚¬ìš©, ì—†ìœ¼ë©´ 'unknown')
        channel = (ota or msg.ota or "unknown") or "unknown"

        # 3) Intent ê¸°ë°˜ í…œí”Œë¦¿ ì„ íƒ (fine_intent, property_code, channel, confidenceê¹Œì§€ ê³ ë ¤)
        template = self._template_repo.get_best_template_for_intent(
            intent=primary_intent,
            fine_intent=fine_intent,
            locale=locale,
            channel=channel,                 # ì˜ˆ: 'airbnb'
            property_code=context.property_code,
            intent_confidence=intent_conf,
        )

        # ê²ŒìŠ¤íŠ¸ ë©”ì‹œì§€ í…ìŠ¤íŠ¸ (LLM ì»¨í…ìŠ¤íŠ¸ìš©)
        guest_message = (
            (msg.pure_guest_message or "").strip()
            or (getattr(msg, "snippet", "") or "").strip()
            or (getattr(msg, "text_body", "") or "").strip()
        )

        # 4) í…œí”Œë¦¿/LLM ì¡°í•©ìœ¼ë¡œ ìµœì¢… reply_text ìƒì„±
        #    - ì›ì¹™: LLM + property_profileì´ í•­ìƒ ì£¼ì¸ê³µ
        #    - í…œí”Œë¦¿ì€ ìˆì„ ê²½ìš° "ì •ì±…/í†¤ ê°€ì´ë“œ"ë¡œë§Œ ì‚¬ìš©
        if use_llm:
            if template:
                # âœ… LLM + í…œí”Œë¦¿ + property_profile
                reply_text = await self._generate_with_llm_and_template(
                    guest_message=guest_message,
                    template_text=template.body_template,
                    context=context,
                    locale=locale,
                )
                generation_mode = "llm_with_template"
            else:
                # âœ… LLM + property_profile only
                reply_text = await self._generate_with_llm_without_template(
                    guest_message=guest_message,
                    context=context,
                    locale=locale,
                )
                generation_mode = "llm_no_template"
        else:
            # âš  LLM ë¯¸ì‚¬ìš© ëª¨ë“œëŠ” ì˜ˆì™¸ì  ìƒí™©(HITL ë””ë²„ê¹… ë“±)ì—ì„œë§Œ ì‚¬ìš©
            if template:
                reply_text = template.body_template
                generation_mode = "template_only"
            else:
                reply_text = self._default_fallback_reply(
                    locale=locale,
                    primary_intent=primary_intent,
                )
                generation_mode = "no_template_fallback"

        # 5) Intent â†’ Action ê²°ì • (ìë™ë°œì†¡ ê°€ëŠ¥ ì—¬ë¶€ ë“±)
        action_decision = self._action_decider.decide(
            primary_intent=primary_intent,
            fine_intent=fine_intent,
            intent_confidence=intent_conf,
            is_ambiguous=is_ambiguous,
        )

        suggestion = AutoReplySuggestion(
            message_id=message_id,
            intent=primary_intent,
            fine_intent=fine_intent,
            intent_confidence=intent_conf,
            reply_text=reply_text,
            template_id=template.id if template else None,
            generation_mode=generation_mode,
            action=action_decision.action,
            allow_auto_send=action_decision.allow_auto_send,
            is_ambiguous=is_ambiguous,
        )

        # 6) ëª¨ë“œ ê²°ì • (AUTOPILOT / HITL)
        send_mode = self._auto_reply_mode  # settings ê¸°ì¤€
        should_auto_send = (
            send_mode == "AUTOPILOT"
            and action_decision.action == MessageActionType.AUTO_REPLY
            and action_decision.allow_auto_send
        )

        # 7) AutoReply ë¡œê·¸ ì €ì¥
        self._auto_reply_log_repo.create_from_suggestion(
            suggestion=suggestion,
            message=msg,
            send_mode=send_mode,
            sent=should_auto_send,
        )

        # 8) ìŠ¤íƒœí”„ ì•Œë¦¼ ìƒì„± & ì €ì¥ (í•„ìš” ì‹œ)
        staff_notification: Optional[StaffNotification] = await self._build_staff_notification(
            message=msg,
            context=context,
            primary_intent=primary_intent,
            fine_intent=fine_intent,
            reply_text=reply_text,
        )

        if staff_notification:
            notif_repo = StaffNotificationRepository(self._db)
            notif_repo.create_from_domain(staff_notification, message_id=msg.id)

        return suggestion

    async def suggest_reply_for_conversation(
        self,
        *,
        thread_id: str,
        ota: Optional[str] = None,
        locale: str = "ko",
        property_code: Optional[str] = None,
        use_llm: bool = True,
        max_messages: int = 20,
    ) -> Optional[AutoReplySuggestion]:
        msgs = (
            self._db.execute(
                select(IncomingMessage)
                .where(IncomingMessage.thread_id == thread_id)
                .order_by(desc(IncomingMessage.received_at), desc(IncomingMessage.id))
            )
            .scalars()
            .all()
        )
        if not msgs:
            return None

        last_guest = None
        for m in msgs:
            direction = getattr(m.direction, "value", None) or str(getattr(m, "direction", "incoming"))
            direction = direction.split(".")[-1]
            if direction == "incoming":
                last_guest = m
                break
        if not last_guest:
            return None

        # âœ… ê¸°ì¡´ message ë‹¨ìœ„ ë¡œì§ê³¼ ë™ì¼í•˜ê²Œ intent í™•ë³´ (ë¶„ë¥˜ê¸° ì§ì ‘ í˜¸ì¶œ ê¸ˆì§€)
        primary_intent, fine_intent, intent_conf, is_ambiguous = self._ensure_intent(
            msg_id=last_guest.id,
            ota=ota or last_guest.ota,
        )

        if primary_intent == MessageIntent.OTHER and not (last_guest.pure_guest_message or "").strip():
            return None

        context = self._context_builder.build_for_conversation(
            thread_id=thread_id,
            primary_intent=primary_intent,
            fine_intent=fine_intent,
            locale=locale,
            explicit_property_code=property_code,
            max_messages=max_messages,
        )

        channel = (ota or last_guest.ota or "unknown") or "unknown"

        template = self._template_repo.get_best_template_for_intent(
            intent=primary_intent,
            fine_intent=fine_intent,
            locale=locale,
            channel=channel,
            property_code=context.property_code,
            intent_confidence=float(intent_conf or 0.0),
        )

        generation_mode = "template"
        if template and template.body:
            reply_text = template.body
            if use_llm:
                reply_text = await self._generate_with_llm_and_template(
                    context=context,
                    template_body=template.body,
                    locale=locale,
                )
                generation_mode = "llm_with_template"
        else:
            if use_llm:
                reply_text = await self._generate_with_llm_without_template(
                    context=context,
                    locale=locale,
                    guest_message = context.pure_guest_message
                )
                generation_mode = "llm_no_template"
            else:
                reply_text = self._default_fallback_reply(
                    locale=locale,
                    primary_intent=primary_intent,
                )
                generation_mode = "no_template_fallback"

        action_decision = self._action_decider.decide(
            primary_intent=primary_intent,
            fine_intent=fine_intent,
            intent_confidence=float(intent_conf or 0.0),
            is_ambiguous=is_ambiguous,
        )

        suggestion = AutoReplySuggestion(
            message_id=last_guest.id,
            intent=primary_intent,
            fine_intent=fine_intent,
            intent_confidence=float(intent_conf or 0.0),
            reply_text=reply_text,
            template_id=getattr(template, "id", None) if template else None,
            generation_mode=generation_mode,
            action=action_decision.action,
            allow_auto_send=action_decision.allow_auto_send,
            is_ambiguous=is_ambiguous,
        )

        self._auto_reply_log_repo.create_from_suggestion(
            suggestion=suggestion,
            message=last_guest,
            send_mode="PREVIEW",
            sent=False,
        )

        # âš ï¸ _ensure_intent ê²½ë¡œëŠ” fine_confidence/reasonsë¥¼ ì£¼ì§€ ì•Šìœ¼ë¯€ë¡œ ë³´ìˆ˜ì ìœ¼ë¡œ ê¸°ë¡
        if fine_intent is not None:
            self._intent_label_repo.create_label(
                message_id=last_guest.id,
                fine_intent=fine_intent,
                confidence=float(intent_conf or 0.0),
                reasons=None,
            )

        return suggestion

    def suggest_reply_for_message_sync(
        self,
        message_id: int,
        ota: str,
        locale: str = "ko",
        property_code: str | None = None,
        use_llm: bool = True,
    ) -> Optional[AutoReplySuggestion]:
        """
        sync ì»¨í…ìŠ¤íŠ¸(ì˜ˆ: GmailOutboxService ë“±)ì—ì„œ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ë˜í¼.
        ë‚´ë¶€ì ìœ¼ë¡œ asyncio.run ìœ¼ë¡œ async ë©”ì„œë“œë¥¼ í˜¸ì¶œí•œë‹¤.
        """
        return asyncio.run(
            self.suggest_reply_for_message(
                message_id=message_id,
                ota=ota,
                locale=locale,
                property_code=property_code,
                use_llm=use_llm,
            )
        )

    # ------------------------------------------------------------------
    # ë‚´ë¶€: Intent í™•ë³´ (DBì— ì—†ìœ¼ë©´ AirbnbIntentClassifierë¡œ ë¶„ë¥˜)
    # ------------------------------------------------------------------

    def _ensure_intent(
        self,
        *,
        msg_id: int,
        ota: Optional[str],
    ) -> Tuple[MessageIntent, Optional[FineGrainedIntent], float, bool]:
        """
        AutoReplyì—ì„œ ì‚¬ìš©í•  Intentë¥¼ ë³´ì¥í•œë‹¤.

        - Airbnb + ê²ŒìŠ¤íŠ¸ + NEEDS_REPLY + pure_guest_message ê°€ ìˆëŠ” ê²½ìš°:
            â†’ AirbnbIntentClassifier(LLM)ë¡œ ì¬ë¶„ë¥˜í•˜ê³ ,
              ê·¸ ê²°ê³¼ë¥¼ incoming_messages ì— ì—…ë°ì´íŠ¸.
        - ê·¸ ì™¸ OTA / ë©”ì‹œì§€ëŠ” DBì— ì €ì¥ëœ intentë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©.
        """

        msg = self._msg_repo.get(msg_id)
        if not msg:
            return MessageIntent.OTHER, None, 0.0, True

        # ê¸°ë³¸ê°’: DBì— ì´ë¯¸ ìˆëŠ” ê°’
        primary_intent: MessageIntent = msg.intent or MessageIntent.OTHER
        intent_conf: float = msg.intent_confidence or 0.0
        fine_intent: Optional[FineGrainedIntent] = msg.fine_intent or None
        is_ambiguous: bool = False

        is_airbnb = (ota == "airbnb") or (msg.ota == "airbnb")
        has_guest_text = bool((msg.pure_guest_message or "").strip())

        if (
            is_airbnb
            and has_guest_text
            and msg.sender_actor == MessageActor.GUEST
            and msg.actionability == MessageActionability.NEEDS_REPLY
        ):
            # âœ… Airbnb ê²ŒìŠ¤íŠ¸ ë©”ì‹œì§€ëŠ” í•­ìƒ ìµœì‹  LLM Intentë¡œ ì¬ë¶„ë¥˜
            hybrid: HybridIntentResult = self._intent_classifier.classify_airbnb_guest_intent(
                pure_guest_message=msg.pure_guest_message,
                subject=msg.subject,
                snippet=None,
            )

            mr = hybrid.message_result
            fr: Optional[FineGrainedIntentResult] = hybrid.fine_result

            primary_intent = mr.intent
            intent_conf = mr.confidence
            is_ambiguous = mr.is_ambiguous

            # fine intent ê²°ê³¼ê°€ ìˆìœ¼ë©´ ê°™ì´ ì—…ë°ì´íŠ¸
            if fr is not None:
                fine_intent = fr.fine_intent

                # DB í•„ë“œ ì—…ë°ì´íŠ¸ (ì˜ˆì™¸ ì•ˆ ë‚˜ê²Œ getattr ì‚¬ìš©)
                msg.fine_intent = fr.fine_intent
                msg.fine_intent_confidence = getattr(fr, "confidence", None)

                reasons = getattr(fr, "reasons", None)
                if reasons is None:
                    reasons = getattr(fr, "reason", None)
                msg.fine_intent_reasons = reasons

            # primary intent ë„ DBì— ë°˜ì˜
            msg.intent = primary_intent
            msg.intent_confidence = intent_conf

            self._db.flush()

        return primary_intent, fine_intent, intent_conf, is_ambiguous
    # ------------------------------------------------------------------
    # ë‚´ë¶€: ReplyContext ì§ë ¬í™” í—¬í¼
    # ------------------------------------------------------------------

    @staticmethod
    def _context_to_dict(context: ReplyContext) -> Dict[str, Any]:
        """
        ReplyContextë¥¼ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ dictë¡œ ë³€í™˜.
        - dataclass / Pydantic / dict ëª¨ë‘ ëŒ€ì‘
        """
        if isinstance(context, dict):
            return context
        if is_dataclass(context):
            return asdict(context)
        if hasattr(context, "model_dump"):
            return context.model_dump()
        if hasattr(context, "dict"):
            return context.dict()
        return {
            k: v for k, v in vars(context).items() if not k.startswith("_")
        }

    # ------------------------------------------------------------------
    # ë‚´ë¶€: LLM ê¸°ë°˜ ë‹µë³€ ìƒì„± (í…œí”Œë¦¿ + ì»¨í…ìŠ¤íŠ¸)
    # ------------------------------------------------------------------

    async def _generate_with_llm_and_template(
        self,
        *,
        guest_message: str,
        template_text: str,
        context: ReplyContext,
        locale: str,
    ) -> str:
        """
        ê¸°ì¡´ í…œí”Œë¦¿ì„ 'ì •ì±…/ê¸°ì¤€ í…ìŠ¤íŠ¸'ë¡œ ì‚¼ê³ ,
        LLMì´ ê·¸ê±¸ ì°¸ê³ í•´ ë‹µë³€ì„ ì¬êµ¬ì„±í•˜ë„ë¡ í•˜ëŠ” ëª¨ë“œ.
        """

        api_key = settings.LLM_API_KEY
        if not api_key:
            return template_text

        from openai import OpenAI

        client = OpenAI(api_key=api_key)
        model_name = settings.LLM_MODEL or "gpt-4.1-mini"

        system_prompt = (
            "ë‹¹ì‹ ì€ ìˆ™ì†Œ í˜¸ìŠ¤íŠ¸ë¥¼ ëŒ€ì‹ í•´ ê²ŒìŠ¤íŠ¸ ë©”ì‹œì§€ì— ë‹µë³€í•˜ëŠ” í•œêµ­ì–´ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\n"
            "ë‹¤ìŒ POLICY_TEXTëŠ” ìˆ™ì†Œì˜ ì •ì±…/ì•ˆë‚´ ë¬¸êµ¬ì…ë‹ˆë‹¤.\n"
            "- POLICY_TEXTì— ì íŒ ì œí•œ ì‚¬í•­, ê·œì¹™, ê¸ˆì§€ ì‚¬í•­ì€ ì ˆëŒ€ ì™„í™”í•˜ê±°ë‚˜ ë³€ê²½í•˜ì§€ ë§ˆì„¸ìš”.\n"
            "- POLICY_TEXTì˜ í•µì‹¬ ë‚´ìš©ì€ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ë˜, ë¬¸ì¥ì„ ìì—°ìŠ¤ëŸ½ê²Œ ë‹¤ë“¬ê³  ì¸ì‚¿ë§ê³¼ ë§ˆë¬´ë¦¬ ë©˜íŠ¸ë§Œ ì¶”ê°€í•˜ì„¸ìš”.\n"
            "- ê²ŒìŠ¤íŠ¸ ì§ˆë¬¸ ë‚´ìš©ê³¼ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì°¸ê³ í•´ ë¶ˆí•„ìš”í•œ ì •ë³´ëŠ” ë¹¼ë„ ì¢‹ì§€ë§Œ, ì •ì±… ìì²´ë¥¼ ë°”ê¾¸ì§€ëŠ” ë§ˆì„¸ìš”.\n"
        )

        policy_block = template_text.strip()
        ctx_dict = self._context_to_dict(context)
        ctx_text = json.dumps(ctx_dict, ensure_ascii=False, default=str)

        user_content = (
            f"[GUEST_MESSAGE]\n{guest_message}\n\n"
            f"[POLICY_TEXT]\n{policy_block}\n\n"
            f"[CONTEXT_JSON]\n{ctx_text}\n\n"
            "ìœ„ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ê²ŒìŠ¤íŠ¸ì—ê²Œ ë³´ë‚¼ ë‹µì¥ì„ í•œêµ­ì–´ë¡œ í•œ ë²ˆë§Œ ì‘ì„±í•´ ì£¼ì„¸ìš”.\n"
            "- POLICY_TEXTì˜ ì •ì±…/ì œí•œ ì‚¬í•­ì€ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ì„¸ìš”.\n"
            "- ì¡´ëŒ“ë§ì„ ì‚¬ìš©í•˜ê³ , 3~6ë¬¸ì¥ ë‚´ë¡œ ì •ë¦¬í•´ ì£¼ì„¸ìš”.\n"
        )

        try:
            resp = client.chat.completions.create(
                model=model_name,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_content},
                ],
            )
            reply_text = (resp.choices[0].message.content or "").strip()
            return reply_text or template_text
        except Exception as exc:  # pragma: no cover
            logger.warning(
                "LLM_AUTOREPLY(template): failed, fallback to template. err=%s",
                exc,
            )
            return template_text

    # ------------------------------------------------------------------
    # ë‚´ë¶€: LLM ê¸°ë°˜ ë‹µë³€ ìƒì„± (í…œí”Œë¦¿ ì—†ìŒ, ì»¨í…ìŠ¤íŠ¸ë§Œ)
    # ------------------------------------------------------------------

    async def _generate_with_llm_without_template(
        self,
        *,
        guest_message: str,
        context: ReplyContext,
        locale: str,
    ) -> str:
        """
        í…œí”Œë¦¿ì´ ì—†ëŠ” ê²½ìš°, ReplyContextë§Œìœ¼ë¡œ LLMì´ ë‹µë³€ì„ ìƒì„±.
        - ì •ì±…/ê°€ê²©/ì•½ì†ì€ ì»¨í…ìŠ¤íŠ¸ì— ìˆëŠ” ì •ë³´ë§Œ ì‚¬ìš©í•˜ë„ë¡ ì œí•œ.
        """

        api_key = settings.LLM_API_KEY
        if not api_key:
            return self._default_fallback_reply(
                locale=locale,
                primary_intent=context.primary_intent,
            )

        from openai import OpenAI

        client = OpenAI(api_key=api_key)
        model_name = settings.LLM_MODEL or "gpt-4.1-mini"

        system_prompt = (
            "You are a professional guest communication assistant for TONO OPERATION, "
            "a hospitality operation company in Korea.\n"
            "You MUST:\n"
            "  - Answer in polite, clear Korean suitable for guests.\n"
            "  - Use ONLY the information provided in the property_profile and context.\n"
            "  - Never invent policies, prices, or promises not present in the context.\n"
            "  - If information is missing, say you will check with the team instead of making it up.\n"
        )

        ctx_dict = self._context_to_dict(context)
        ctx_text = json.dumps(ctx_dict, ensure_ascii=False, default=str)

        user_content = (
            f"[GUEST_MESSAGE]\n{guest_message}\n\n"
            f"[CONTEXT_JSON]\n{ctx_text}\n\n"
            "ìœ„ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ê²ŒìŠ¤íŠ¸ì—ê²Œ ë³´ë‚¼ ë‹µì¥ì„ í•œêµ­ì–´ë¡œ í•œ ë²ˆë§Œ ì‘ì„±í•´ ì£¼ì„¸ìš”.\n"
            "- ì»¨í…ìŠ¤íŠ¸ì— ì—†ëŠ” ì •ì±…/ê°€ê²©/ì•½ì†ì€ ë§Œë“¤ì§€ ë§ˆì„¸ìš”.\n"
            "- ì •ë³´ê°€ ë¶€ì¡±í•˜ë©´ í™•ì¸ í›„ ë‹¤ì‹œ ì•ˆë‚´ë“œë¦¬ê² ë‹¤ê³  ë‹µë³€í•´ ì£¼ì„¸ìš”.\n"
        )

        try:
            resp = client.chat.completions.create(
                model=model_name,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_content},
                ],
            )
            reply_text = (resp.choices[0].message.content or "").strip()
            if reply_text:
                return reply_text
        except Exception as exc:  # pragma: no cover
            logger.warning(
                "LLM_AUTOREPLY(no_template): failed, fallback to default. err=%s",
                exc,
            )

        return self._default_fallback_reply(
            locale=locale,
            primary_intent=context.primary_intent,
        )

    # ------------------------------------------------------------------
    #  LLM ê¸°ë°˜ follow-up ì¶”ì¶œ
    # ------------------------------------------------------------------

    async def _extract_follow_up_actions_with_llm(
        self,
        *,
        message_text: str,
        primary_intent: MessageIntent,
        fine_intent: Optional[FineGrainedIntent],
        reply_text: str,
        context: ReplyContext,
    ) -> list[str]:
        """
        LLMì„ ì‚¬ìš©í•´ì„œ ìŠ¤íƒœí”„ê°€ í•´ì•¼ í•  follow-up ì‘ì—… ë¦¬ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•œë‹¤.
        """

        api_key = settings.LLM_API_KEY
        if not api_key:
            return self._rule_based_follow_up_actions(
                message_text=message_text,
                primary_intent=primary_intent,
                fine_intent=fine_intent,
            )

        from openai import OpenAI

        client = OpenAI(api_key=api_key)
        model_name = settings.LLM_MODEL or "gpt-4.1-mini"

        ctx_dict = self._context_to_dict(context)
        ctx_text = json.dumps(ctx_dict, ensure_ascii=False, default=str)

        system_prompt = (
            "ë‹¹ì‹ ì€ ìˆ™ì†Œ ìš´ì˜íŒ€(ë°±ì˜¤í”¼ìŠ¤) ì „ìš© ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\n"
            "ê²ŒìŠ¤íŠ¸ ë©”ì‹œì§€ì™€ í˜¸ìŠ¤íŠ¸ê°€ ë³´ë‚¸ ë‹µì¥ì„ ë³´ê³ , ìš´ì˜íŒ€ì´ í›„ì†ìœ¼ë¡œ ì²˜ë¦¬í•´ì•¼ í•  ì—…ë¬´ ëª©ë¡ì„ ì¶”ì¶œí•´ ì£¼ì„¸ìš”.\n"
            "ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ëœ ì§§ì€ ì‘ì—… ì„¤ëª… ë¦¬ìŠ¤íŠ¸ë¥¼ JSON ë°°ì—´ í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•´ì•¼ í•©ë‹ˆë‹¤.\n"
            "ì˜ˆ: [\"ìì¿ ì§€ ë¹„ìš© ì…ê¸ˆ í™•ì¸\", \"ëƒ‰ì¥ê³  ë‚´ ìŒë£Œ ì œê³µ ì—¬ë¶€ í™•ì¸\"]\n"
            "- ê²ŒìŠ¤íŠ¸ì—ê²Œ ë‹µì¥í•˜ëŠ” ë¬¸ì¥ì€ ì ˆëŒ€ ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”.\n"
            "- ì‚¬ëŒì´ ì‹¤ì œë¡œ í•´ì•¼ í•  \"ì‹¤ë¬´ ì—…ë¬´\"ë§Œ ë‹´ìœ¼ì„¸ìš”.\n"
            "- ì•„ë¬´ í•  ì¼ì´ ì—†ë‹¤ë©´ ë¹ˆ ë°°ì—´ []ë§Œ ì¶œë ¥í•˜ì„¸ìš”.\n"
        )

        user_content = (
            f"[PRIMARY_INTENT] {primary_intent.name}\n"
            f"[FINE_INTENT] {fine_intent.name if fine_intent else 'NONE'}\n\n"
            f"[GUEST_MESSAGE]\n{message_text}\n\n"
            f"[GUEST_REPLY_TEXT]\n{reply_text}\n\n"
            f"[CONTEXT_JSON]\n{ctx_text}\n\n"
            "ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìš´ì˜íŒ€ì´ í›„ì†ìœ¼ë¡œ ì²˜ë¦¬í•´ì•¼ í•  ì—…ë¬´(Task)ë¥¼ JSON ë°°ì—´ í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•´ ì£¼ì„¸ìš”.\n"
            "ì˜ˆì™¸ ì—†ì´ ë‹¤ìŒ í˜•ì‹ë§Œ í—ˆìš©ë©ë‹ˆë‹¤:\n"
            "[\"ì²« ë²ˆì§¸ ì‘ì—…\", \"ë‘ ë²ˆì§¸ ì‘ì—…\"]\n"
        )

        raw = ""
        try:
            resp = client.chat.completions.create(
                model=model_name,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_content},
                ],
            )
            raw = (resp.choices[0].message.content or "").strip()

            start = raw.find("[")
            end = raw.rfind("]")
            if start == -1 or end == -1 or end <= start:
                raise ValueError("no json array in llm output")

            json_str = raw[start : end + 1]
            tasks = json.loads(json_str)

            tasks = [str(t).strip() for t in tasks if str(t).strip()]
            if tasks:
                return tasks

        except Exception as exc:  # pragma: no cover
            logger.warning(
                "LLM_STAFF_FOLLOWUP: failed or invalid JSON. raw=%r err=%s",
                raw,
                exc,
            )

        return self._rule_based_follow_up_actions(
            message_text=message_text,
            primary_intent=primary_intent,
            fine_intent=fine_intent,
        )

    #------------------------------------------------------------------
    # LLM ì‹¤íŒ¨ì‹œ follow-up action ê°ì§€
    #------------------------------------------------------------------

    def _rule_based_follow_up_actions(
        self,
        *,
        message_text: str,
        primary_intent: MessageIntent,
        fine_intent: Optional[FineGrainedIntent],
    ) -> list[str]:
        """
        LLMì´ ì‹¤íŒ¨í–ˆì„ ë•Œë§Œ ì‚¬ìš©í•˜ëŠ” ì•„ì£¼ ì–‡ì€ ë°±ì—…ìš© ê·œì¹™.
        """
        text = (message_text or "").strip()
        actions: list[str] = []

        if not text:
            return actions

        if any(k in text for k in ["ì´ì²´", "ì…ê¸ˆ", "ì†¡ê¸ˆ", "ê²°ì œ"]):
            actions.append("ê²°ì œ/ì…ê¸ˆ ë‚´ì—­ í™•ì¸")

        if any(k in text for k in ["ì¶©ì „ê¸°", "ì¼€ì´ë¸”", "ì¶©ì „"]):
            actions.append("íœ´ëŒ€í° ì¶©ì „ê¸°/ì¼€ì´ë¸” ë¹„ì¹˜ ì—¬ë¶€ í™•ì¸")

        if any(k in text for k in ["ëƒ‰ì¥ê³ ", "ìŒë£Œ", "ë§¥ì£¼", "ìˆ ", "ë“œë§í¬"]):
            actions.append("ëƒ‰ì¥ê³  ë‚´ ìŒë£Œ ë° ì£¼ë¥˜ ì œê³µ ì—¬ë¶€ í™•ì¸")

        if any(k in text for k in ["ì²´í¬ì¸", "ì…ì‹¤", "ì²´í¬ì•„ì›ƒ", "í‡´ì‹¤"]):
            actions.append("ì²´í¬ì¸/ì²´í¬ì•„ì›ƒ ì‹œê°„ ë° ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸")

        if "ë°˜ë ¤" in text or "ì• ê²¬" in text or "ê°•ì•„ì§€" in text or "ê³ ì–‘ì´" in text:
            actions.append("ë°˜ë ¤ë™ë¬¼ ë™ë°˜ ê°€ëŠ¥ ì—¬ë¶€ ë° ìš”ê¸ˆ í™•ì¸")

        if any(k in text for k in ["ë¶ˆí¸", "ë¬¸ì œ", "ê³ ì¥", "ì•ˆë¼", "ì•ˆ ë¼", "ìƒˆëŠ”", "ëƒ„ìƒˆ"]):
            actions.append("í˜„ì¥ ì‹œì„¤/ì¥ë¹„ ìƒíƒœ í™•ì¸ ë° ì¡°ì¹˜ í•„ìš” ì—¬ë¶€ í™•ì¸")

        return list(dict.fromkeys(actions))

    # ------------------------------------------------------------------
    # ë‚´ë¶€: ê¸°ë³¸ Fallback ë¬¸êµ¬
    # ------------------------------------------------------------------

    def _default_fallback_reply(
        self,
        *,
        locale: str,
        primary_intent: MessageIntent,
    ) -> str:
        """
        í…œí”Œë¦¿ë„ ì—†ê³ , LLMë„ ì•ˆ ì“´ ê²½ìš°ì— ì‚¬ìš©í•  ì•„ì£¼ ê¸°ë³¸ì ì¸ ë¬¸êµ¬.
        """

        if locale.startswith("ko"):
            if primary_intent == MessageIntent.CHECKIN_QUESTION:
                return (
                    "ì•ˆë…•í•˜ì„¸ìš”, ë¬¸ì˜ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤. ì²´í¬ì¸ ê°€ëŠ¥ ì‹œê°„ê³¼ ì…ì‹¤ ë°©ë²•ì„ í™•ì¸í•˜ì—¬ ë‹¤ì‹œ ì•ˆë‚´ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
                )
            if primary_intent == MessageIntent.CHECKOUT_QUESTION:
                return (
                    "ì•ˆë…•í•˜ì„¸ìš”, ì²´í¬ì•„ì›ƒ ì‹œê°„ ê´€ë ¨ ë¬¸ì˜ ê°ì‚¬ë“œë¦½ë‹ˆë‹¤. í˜„ì¬ ì˜ˆì•½ ì •ë³´ì™€ ìš´ì˜ ìƒí™©ì„ í™•ì¸í•˜ì—¬ ì•ˆë‚´ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
                )
            if primary_intent == MessageIntent.LOCATION_QUESTION:
                return (
                    "ì•ˆë…•í•˜ì„¸ìš”, ìˆ™ì†Œ ìœ„ì¹˜ ë° ì£¼ì°¨ ê´€ë ¨ ë¬¸ì˜ ê°ì‚¬ë“œë¦½ë‹ˆë‹¤. ì •í™•í•œ ìœ„ì¹˜ì™€ ì£¼ì°¨ ê°€ëŠ¥ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ì—¬ ì•ˆë‚´ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
                )
            if primary_intent == MessageIntent.AMENITY_QUESTION:
                return (
                    "ì•ˆë…•í•˜ì„¸ìš”, ê°ì‹¤ ë‚´ í¸ì˜ì‹œì„¤ ê´€ë ¨ ë¬¸ì˜ ê°ì‚¬ë“œë¦½ë‹ˆë‹¤. ì´ìš© ê°€ëŠ¥ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ì—¬ ë‹¤ì‹œ ì•ˆë‚´ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
                )
            if primary_intent == MessageIntent.PET_POLICY_QUESTION:
                return (
                    "ì•ˆë…•í•˜ì„¸ìš”, ë°˜ë ¤ë™ë¬¼ ë™ë°˜ ê´€ë ¨ ë¬¸ì˜ ê°ì‚¬ë“œë¦½ë‹ˆë‹¤. í•´ë‹¹ ìˆ™ì†Œì˜ ë°˜ë ¤ë™ë¬¼ ì •ì±…ì„ í™•ì¸í•˜ì—¬ ì•ˆë‚´ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
                )
            if primary_intent == MessageIntent.HOUSE_RULE_QUESTION:
                return (
                    "ì•ˆë…•í•˜ì„¸ìš”, ìˆ™ì†Œ ì´ìš© ê·œì¹™ ê´€ë ¨ ë¬¸ì˜ ê°ì‚¬ë“œë¦½ë‹ˆë‹¤. í•˜ìš°ìŠ¤ ë£°ì„ í™•ì¸í•˜ì—¬ ë‹¤ì‹œ ìì„¸íˆ ì•ˆë‚´ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
                )
            if primary_intent == MessageIntent.RESERVATION_CHANGE:
                return (
                    "ì•ˆë…•í•˜ì„¸ìš”, ì˜ˆì•½ ë³€ê²½ ê´€ë ¨ ë¬¸ì˜ ê°ì‚¬ë“œë¦½ë‹ˆë‹¤. í˜„ì¬ ì˜ˆì•½ ì •ë³´ì™€ ê°€ëŠ¥ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ì—¬ ì•ˆë‚´ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
                )
            if primary_intent == MessageIntent.CANCELLATION:
                return (
                    "ì•ˆë…•í•˜ì„¸ìš”, ì˜ˆì•½ ì·¨ì†Œ ê´€ë ¨ ë¬¸ì˜ ê°ì‚¬ë“œë¦½ë‹ˆë‹¤. ì·¨ì†Œ ë° í™˜ë¶ˆ ê·œì •ì„ í™•ì¸í•˜ì—¬ ì•ˆë‚´ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
                )
            if primary_intent == MessageIntent.COMPLAINT:
                return (
                    "ë¶ˆí¸ì„ ë“œë ¤ ì •ë§ ì£„ì†¡í•©ë‹ˆë‹¤. ë§ì”€í•´ ì£¼ì‹  ë‚´ìš©ì€ ë°”ë¡œ í™•ì¸í•˜ì—¬ ê°€ëŠ¥í•œ ì¡°ì¹˜ë¥¼ ì•ˆë‚´ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
                )
            if primary_intent == MessageIntent.THANKS_OR_GOOD_REVIEW:
                return (
                    "ë”°ëœ»í•œ ë§ì”€ ê°ì‚¬í•©ë‹ˆë‹¤. í¸ì•ˆí•œ ì‹œê°„ ë³´ë‚´ì‹¤ ìˆ˜ ìˆë„ë¡ ëê¹Œì§€ ì˜ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
                )
            if primary_intent == MessageIntent.GENERAL_QUESTION:
                return (
                    "ì•ˆë…•í•˜ì„¸ìš”, ê²ŒìŠ¤íŠ¸ë‹˜,ë¬¸ì˜ ì£¼ì…”ì„œ ê°ì‚¬ë“œë¦¬ë©°, ë‚´ìš©ì„ í™•ì¸í•œ ë’¤ ë¹ ë¥´ê²Œ ì•ˆë‚´ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
                )

            return (
                "ì•ˆë…•í•˜ì„¸ìš”, ê²ŒìŠ¤íŠ¸ë‹˜,ë¬¸ì˜ ì£¼ì…”ì„œ ê°ì‚¬ë“œë¦¬ë©°, ë‚´ìš©ì„ í™•ì¸í•œ ë’¤ ë¹ ë¥´ê²Œ ì•ˆë‚´ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
            )

        return "Thank you for your message. We will review your request and get back to you as soon as possible."
